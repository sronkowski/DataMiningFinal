{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview, Credits, Genres and Keywords Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JC\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.distplot(year, color='steelblue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-02-03\n",
       "1   2017-02-03\n",
       "Name: release_latest, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['release_latest']=df2['release_date'][4255] \n",
    "df2['release_latest'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2613\n",
       "1    3549\n",
       "2     467\n",
       "3    1664\n",
       "4    1795\n",
       "Name: days, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['days']=(df2['release_latest']-df2['release_date']).dt.days+1\n",
    "df2['days'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def standardize(df):   \n",
    "    standardscaler = StandardScaler().fit(df)\n",
    "    scaled = standardscaler.transform(df)\n",
    "    return scaled\n",
    "\n",
    "df2['year_standard']=standardize(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.526158\n",
       "1    0.365038\n",
       "2    1.009520\n",
       "3    0.767839\n",
       "4    0.767839\n",
       "Name: year_standard, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['year_standard'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 20977)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "df2['overview'] = df2['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df2['overview'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the stringified features into their corresponding python objects\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the director's name from the crew feature. If director is not listed, return NaN\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the list top 3 elements or entire list; whichever is more.\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "df2['director'] = df2['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(get_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "      <th>director</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>[Sam Worthington, Zoe Saldana, Sigourney Weaver]</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>[culture clash, future, space war]</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[Johnny Depp, Orlando Bloom, Keira Knightley]</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>[ocean, drug abuse, exotic island]</td>\n",
       "      <td>[Adventure, Fantasy, Action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>[Daniel Craig, Christoph Waltz, Léa Seydoux]</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>[spy, based on novel, secret agent]</td>\n",
       "      <td>[Action, Adventure, Crime]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                               cast        director  \\\n",
       "0  [Sam Worthington, Zoe Saldana, Sigourney Weaver]   James Cameron   \n",
       "1     [Johnny Depp, Orlando Bloom, Keira Knightley]  Gore Verbinski   \n",
       "2      [Daniel Craig, Christoph Waltz, Léa Seydoux]      Sam Mendes   \n",
       "\n",
       "                              keywords                        genres  \n",
       "0   [culture clash, future, space war]  [Action, Adventure, Fantasy]  \n",
       "1   [ocean, drug abuse, exotic island]  [Adventure, Fantasy, Action]  \n",
       "2  [spy, based on novel, secret agent]    [Action, Adventure, Crime]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the new features of the first 3 films\n",
    "df2[['title', 'cast', 'director', 'keywords', 'genres']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['director'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4697,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cast'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('tmdb_5000_movies_credits_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Overview Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim_overview = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.02160043, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.01487817, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.02160043, 0.01487817, ..., 1.        , 0.01608697,\n",
       "        0.00701708],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01608697, 1.        ,\n",
       "        0.01171577],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00701708, 0.01171577,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"cosine_sim_overview.csv\", cosine_sim_overview , delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Director / Actor Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_director_list(x):\n",
    "    return ' '.join(x['cast']) + ' ' + x['director'] \n",
    "df2['cast_director_list'] = df2.apply(cast_director_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df2['cast_director_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim_cast_director = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_cast_director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"cosine_sim_cast_director.csv\", cosine_sim_cast_director, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_list(x):\n",
    "    return ' '.join(x['genres'])\n",
    "df2['genre_list'] = df2.apply(genre_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df2['genre_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_genre = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.66666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 0.66666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.66666667, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"cosine_sim_genre.csv\", cosine_sim_genre, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_mixed=cosine_sim_genre+cosine_sim_cast_director+cosine_sim_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        , 1.        , 0.66666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 3.        , 0.66666667, ..., 0.02160043, 0.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.66666667, 3.        , ..., 0.01487817, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.02160043, 0.01487817, ..., 3.        , 0.01608697,\n",
       "        0.00701708],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01608697, 2.        ,\n",
       "        0.01171577],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00701708, 0.01171577,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"cosine_sim_mixed.csv\", cosine_sim_mixed, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender I - mixed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df2.index, index=df2['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of our main DataFrame and construct reverse mapping as before\n",
    "df2 = df2.reset_index()\n",
    "indices = pd.Series(df2.index, index=df2['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations_matrix(title, cosine_sim=cosine_sim_mixed): \n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 20 most similar movies\n",
    "    sim_scores = sim_scores[1:21]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df2['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119                             Batman Begins\n",
       "65                            The Dark Knight\n",
       "3073                        Romeo Is Bleeding\n",
       "1196                             The Prestige\n",
       "1253                            Kiss of Death\n",
       "761                            Righteous Kill\n",
       "1149                          American Hustle\n",
       "1742                           Brick Mansions\n",
       "3062                              Deuces Wild\n",
       "2543                                 Cop Land\n",
       "2388                               I Am Wrath\n",
       "2154                             Street Kings\n",
       "405     The Fast and the Furious: Tokyo Drift\n",
       "1765                          The Newton Boys\n",
       "3326                           Black November\n",
       "1278                               The Gunman\n",
       "3828                        Menace II Society\n",
       "4663                                  Bronson\n",
       "4408                           Jimmy and Judy\n",
       "3074                                The Limey\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_matrix('The Dark Knight Rises', cosine_sim_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise (from surprise)\n",
      "  Using cached https://files.pythonhosted.org/packages/4d/fc/cd4210b247d1dca421c25994740cbbf03c5e980e31881f10eaddf45fdab0/scikit-surprise-1.0.6.tar.gz\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cahib\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\cahib\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.16.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\cahib\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\cahib\\appdata\\roaming\\python\\python37\\site-packages (from scikit-surprise->surprise) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Complete output from command C:\\Users\\cahib\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\cahib\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a9nt1ox7\\\\scikit-surprise\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\cahib\\AppData\\Local\\Temp\\pip-wheel-8lmpe6nh --python-tag cp37:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\evaluate.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "  creating build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-3.7\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "  Running setup.py install for scikit-surprise: started\n",
      "    Running setup.py install for scikit-surprise: finished with status 'error'\n",
      "    Complete output from command C:\\Users\\cahib\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\cahib\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a9nt1ox7\\\\scikit-surprise\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\cahib\\AppData\\Local\\Temp\\pip-record-7j0g9v17\\install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.7\n",
      "    creating build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\accuracy.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\dataset.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\dump.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\evaluate.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\reader.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\trainset.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\utils.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\__main__.py -> build\\lib.win-amd64-3.7\\surprise\n",
      "    creating build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\\model_selection\n",
      "    creating build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    running egg_info\n",
      "    writing scikit_surprise.egg-info\\PKG-INFO\n",
      "    writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "    writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "    writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "    writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "    reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "    copying surprise\\similarities.c -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\similarities.pyx -> build\\lib.win-amd64-3.7\\surprise\n",
      "    copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-3.7\\surprise\\prediction_algorithms\n",
      "    running build_ext\n",
      "    building 'surprise.similarities' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for scikit-surprise\n",
      "Command \"C:\\Users\\cahib\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\cahib\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a9nt1ox7\\\\scikit-surprise\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\cahib\\AppData\\Local\\Temp\\pip-record-7j0g9v17\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\cahib\\AppData\\Local\\Temp\\pip-install-a9nt1ox7\\scikit-surprise\\\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender II - mixed matrix + rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating =pd.DataFrame(df2['vote_average'],index=df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_average\n",
       "0           7.2\n",
       "1           6.9\n",
       "2           6.3\n",
       "3           7.6\n",
       "4           6.1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.928811\n",
       "1    0.677001\n",
       "2    0.173380\n",
       "3    1.264558\n",
       "4    0.005506\n",
       "Name: vote_average_standard, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def standardize(df):   \n",
    "    standardscaler = StandardScaler().fit(df)\n",
    "    scaled = standardscaler.transform(df)\n",
    "    return scaled\n",
    "df2['vote_average_standard']=standardize(rating)\n",
    "df2['vote_average_standard'].head()\n",
    "\n",
    "##bad result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.72\n",
       "1    0.69\n",
       "2    0.63\n",
       "3    0.76\n",
       "4    0.61\n",
       "Name: vote_average, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_ = pd.Series(df2['vote_average']/df2['vote_average'].max(),index=df2.index)\n",
    "rating_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations_rating(title, cosine_sim=cosine_sim_mixed):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    rating = rating_[idx]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))+rating\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 20 most similar movies\n",
    "    sim_scores = sim_scores[1:21]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df2['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119                             Batman Begins\n",
       "65                            The Dark Knight\n",
       "3073                        Romeo Is Bleeding\n",
       "1196                             The Prestige\n",
       "1253                            Kiss of Death\n",
       "761                            Righteous Kill\n",
       "1149                          American Hustle\n",
       "1742                           Brick Mansions\n",
       "3062                              Deuces Wild\n",
       "2543                                 Cop Land\n",
       "2388                               I Am Wrath\n",
       "2154                             Street Kings\n",
       "405     The Fast and the Furious: Tokyo Drift\n",
       "1765                          The Newton Boys\n",
       "3326                           Black November\n",
       "1278                               The Gunman\n",
       "3828                        Menace II Society\n",
       "4663                                  Bronson\n",
       "4408                           Jimmy and Judy\n",
       "3074                                The Limey\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_rating('The Dark Knight Rises', cosine_sim_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender III - mixed matrix + rating + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = pd.Series(df2['days'], index=df2.index)\n",
    "year = np.array(df2['days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.6671326498912707),\n",
       " (1, 0.6669911313000219),\n",
       " (2, inf),\n",
       " (3, 0.6675020885547203),\n",
       " (4, 0.6674196787148596),\n",
       " (5, 0.6669892473118282),\n",
       " (6, 0.0005564830272676684),\n",
       " (7, 0.7029628974442613),\n",
       " (8, 0.3585971183492162),\n",
       " (9, 0.67337807606264),\n",
       " (10, 0.6669601800215245),\n",
       " (11, 1.082146995357077),\n",
       " (12, 0.6669594924353345),\n",
       " (13, 0.6678500986193295),\n",
       " (14, 0.6678214010777523),\n",
       " (15, 0.33370098039215695),\n",
       " (16, 0.6674485274954394),\n",
       " (17, 0.7194292200255402),\n",
       " (18, 0.36752278420872336),\n",
       " (19, 0.6697916666666669),\n",
       " (20, 0.6674890350877195),\n",
       " (21, 0.8169983370742389),\n",
       " (22, 0.40971027876795657),\n",
       " (23, 0.6769239323077857),\n",
       " (24, 0.6669442131557037),\n",
       " (25, 0.00015264845061822624),\n",
       " (26, 0.6721014492753625),\n",
       " (27, 0.6674400618716165),\n",
       " (28, 0.6738609112709834),\n",
       " (29, 1.301690119692245),\n",
       " (30, 0.6669082125603867),\n",
       " (31, 0.6677524429967429),\n",
       " (32, 0.33381806430764266),\n",
       " (33, 0.6669571954290143),\n",
       " (34, 0.0011655011655011655),\n",
       " (35, 0.7428023719968636),\n",
       " (36, 0.6842330654468758),\n",
       " (37, 0.3343717549325027),\n",
       " (38, 0.6820103546394293),\n",
       " (39, 0.667228148979974),\n",
       " (40, 0.3339591155611182),\n",
       " (41, 0.6672944130571251),\n",
       " (42, 0.0005107252298263534),\n",
       " (43, 0.3509865308586917),\n",
       " (44, 0.5821579614973181),\n",
       " (45, 0.3344988344988346),\n",
       " (46, 0.7232398389283002),\n",
       " (47, 0.6940191919802862),\n",
       " (48, 0.33436319945073817),\n",
       " (49, 0.0011123470522803114),\n",
       " (50, 0.7109993466208461),\n",
       " (51, 0.6892292071381212),\n",
       " (52, 0.6672991777356105),\n",
       " (53, 0.8168650407656037),\n",
       " (54, 0.38596491228070184),\n",
       " (55, 0.33415166393889806),\n",
       " (56, 0.6705882352941178),\n",
       " (57, 0.0003728560775540641),\n",
       " (58, 0.6954498616285774),\n",
       " (59, 0.6671197704274281),\n",
       " (60, 0.03497367128089526),\n",
       " (61, 0.3371212121212122),\n",
       " (62, 1.0705451639236774),\n",
       " (63, 0.3336103416435827),\n",
       " (64, 0.004878048780487805),\n",
       " (65, 0.6670428893905194),\n",
       " (66, 0.00042426813746287653),\n",
       " (67, 0.33374792703150924),\n",
       " (68, 0.6670322973796468),\n",
       " (69, 0.35377012195133994),\n",
       " (70, 0.6668343674884009),\n",
       " (71, 0.6670407781518894),\n",
       " (72, 1.0035587188612103),\n",
       " (73, 0.0003266906239790918),\n",
       " (74, 0.4101825264406522),\n",
       " (75, 0.8166318074321209),\n",
       " (76, 0.7004350528563887),\n",
       " (77, 0.007194244604316547),\n",
       " (78, 0.3626065093999664),\n",
       " (79, 0.6671649227703041),\n",
       " (80, 0.3560362356659761),\n",
       " (81, 0.6686046511627909),\n",
       " (82, 0.36999328085951577),\n",
       " (83, 0.6705882352941178),\n",
       " (84, 0.6681180454765362),\n",
       " (85, 0.6817351520412862),\n",
       " (86, 0.333836098541981),\n",
       " (87, 0.3395833333333334),\n",
       " (88, 0.40230536456698374),\n",
       " (89, 0.0009182736455463728),\n",
       " (90, 0.3335832083958022),\n",
       " (91, 0.6708333333333335),\n",
       " (92, 0.3338185346918972),\n",
       " (93, 0.3335556049492481),\n",
       " (94, 0.6688741721854307),\n",
       " (95, 0.3361502347417841),\n",
       " (96, 0.33385146804835936),\n",
       " (97, 0.6947197903624633),\n",
       " (98, 0.667606516290727),\n",
       " (99, 0.6668575427880641),\n",
       " (100, 0.0003957261574990107),\n",
       " (101, 0.6672854785478549),\n",
       " (102, 0.710144927536232),\n",
       " (103, 0.6830017016785068),\n",
       " (104, 0.6669561860644665),\n",
       " (105, 0.0047169811320754715),\n",
       " (106, 0.3336575875486382),\n",
       " (107, 0.6713836477987424),\n",
       " (108, 0.3969036181320429),\n",
       " (109, 0.33385964912280713),\n",
       " (110, 0.00018971732119142478),\n",
       " (111, 0.6669952897360063),\n",
       " (112, 0.3335838971018125),\n",
       " (113, 0.3336620644312953),\n",
       " (114, 0.3336079077429984),\n",
       " (115, 0.4086224019490856),\n",
       " (116, 0.36562924771673055),\n",
       " (117, 0.33359950314967624),\n",
       " (118, 0.00032808398950131233),\n",
       " (119, 0.6669305189094109),\n",
       " (120, 0.00039184952978056425),\n",
       " (121, 0.6980042833554214),\n",
       " (122, 0.6670882518268693),\n",
       " (123, 0.6668953426328228),\n",
       " (124, 0.3347659980897804),\n",
       " (125, 0.6668865918920902),\n",
       " (126, 0.6680421824850987),\n",
       " (127, 0.672690763052209),\n",
       " (128, 0.05111878825218867),\n",
       " (129, 0.7115934959526051),\n",
       " (130, 0.33372859025032947),\n",
       " (131, 0.6815138282612636),\n",
       " (132, 0.5781147951835096),\n",
       " (133, 0.0007898894154818325),\n",
       " (134, 0.7232340658505678),\n",
       " (135, 0.00048007681228996637),\n",
       " (136, 0.3336757990867581),\n",
       " (137, 0.035013302585024865),\n",
       " (138, 0.667181069958848),\n",
       " (139, 0.666955433631726),\n",
       " (140, 0.3758792028650512),\n",
       " (141, 0.33392434988179676),\n",
       " (142, 0.3336371923427531),\n",
       " (143, 0.3645833333333334),\n",
       " (144, 0.3349307774227903),\n",
       " (145, 0.3335723962068692),\n",
       " (146, 0.0008084074373484236),\n",
       " (147, 0.7712181920434175),\n",
       " (148, 0.3371501272264632),\n",
       " (149, 0.3334914111075984),\n",
       " (150, 0.6882630582945001),\n",
       " (151, 0.6670100732600734),\n",
       " (152, 0.6779026217228467),\n",
       " (153, 0.667371388301621),\n",
       " (154, 0.028279918984151664),\n",
       " (155, 0.00027808676307007786),\n",
       " (156, 0.3335635889170313),\n",
       " (157, 0.669724770642202),\n",
       " (158, 0.6670896785109985),\n",
       " (159, 0.4084512949299613),\n",
       " (160, 0.6801639830382881),\n",
       " (161, 0.00819672131147541),\n",
       " (162, 0.6004651097527987),\n",
       " (163, 0.3951551406201507),\n",
       " (164, 0.6668249696585934),\n",
       " (165, 0.3553095060741626),\n",
       " (166, 0.6925250005855064),\n",
       " (167, 0.6669260700389107),\n",
       " (168, 0.6668579078217635),\n",
       " (169, 0.6955184191949938),\n",
       " (170, 0.7684804781334267),\n",
       " (171, 0.5775794167606616),\n",
       " (172, 0.33426183844011154),\n",
       " (173, 0.01806022174148327),\n",
       " (174, 0.6670381376919269),\n",
       " (175, 0.3378995433789955),\n",
       " (176, 0.3500000000000001),\n",
       " (177, 0.0011947431302270011),\n",
       " (178, 0.0005885815185403178),\n",
       " (179, 0.4022538234332979),\n",
       " (180, 0.37568082397512126),\n",
       " (181, 0.3337037037037038),\n",
       " (182, 0.6891635889969427),\n",
       " (183, 0.6680751173708922),\n",
       " (184, 0.0045045045045045045),\n",
       " (185, 0.3335984446800991),\n",
       " (186, 0.6668897315785562),\n",
       " (187, 0.6673520676262282),\n",
       " (188, 0.3702409790331806),\n",
       " (189, 0.4099576921732647),\n",
       " (190, 0.5934940586065752),\n",
       " (191, 0.3335734293717488),\n",
       " (192, 0.01875631540891589),\n",
       " (193, 0.6678043230944257),\n",
       " (194, 0.000177367860943597),\n",
       " (195, 0.33652822151224715),\n",
       " (196, 0.33388157894736853),\n",
       " (197, 0.355414411706956),\n",
       " (198, 0.33453815261044184),\n",
       " (199, 0.6668892846542003),\n",
       " (200, 0.3362573099415206),\n",
       " (201, 0.043165560074160725),\n",
       " (202, 0.3350398179749717),\n",
       " (203, 0.6668855808523061),\n",
       " (204, 0.6672727272727275),\n",
       " (205, 1.0006973500697351),\n",
       " (206, 0.6671583087512293),\n",
       " (207, 0.6862827621126534),\n",
       " (208, 0.6668360433604338),\n",
       " (209, 0.40910007922025143),\n",
       " (210, 0.7022364758215697),\n",
       " (211, 0.00018328445747800586),\n",
       " (212, 0.6669064748201441),\n",
       " (213, 0.6668441919640217),\n",
       " (214, 0.0001753463089601964),\n",
       " (215, 0.6669937847562972),\n",
       " (216, 0.6676012461059192),\n",
       " (217, 0.33364839319470707),\n",
       " (218, 0.5062549014533181),\n",
       " (219, 0.666888691533452),\n",
       " (220, 0.33413719185423374),\n",
       " (221, 0.33353964651674584),\n",
       " (222, 0.334567901234568),\n",
       " (223, 0.4690507717402187),\n",
       " (224, 0.40982557753010906),\n",
       " (225, 0.3337001711910003),\n",
       " (226, 0.02170517694302003),\n",
       " (227, 0.43852265721938244),\n",
       " (228, 0.6851136395509235),\n",
       " (229, 0.6851140639799389),\n",
       " (230, 0.6668702497285561),\n",
       " (231, 0.02821471573705806),\n",
       " (232, 0.6678787878787881),\n",
       " (233, 0.6668332222962471),\n",
       " (234, 0.3343859649122808),\n",
       " (235, 0.3336850744518702),\n",
       " (236, 0.3335381674177251),\n",
       " (237, 0.6728016359918202),\n",
       " (238, 0.6689138576779028),\n",
       " (239, 0.0013175230566534915),\n",
       " (240, 0.6668129724457451),\n",
       " (241, 0.6895333353514095),\n",
       " (242, 0.6788617886178864),\n",
       " (243, 0.6669703411276446),\n",
       " (244, 0.3399122807017545),\n",
       " (245, 0.6668198529411766),\n",
       " (246, 0.0001786352268667381),\n",
       " (247, 0.40849998943189725),\n",
       " (248, 0.34753285342458085),\n",
       " (249, 0.33783783783783794),\n",
       " (250, 0.00025220680958385876),\n",
       " (251, 0.0005662514156285391),\n",
       " (252, 0.9307720435849879),\n",
       " (253, 0.423367408503453),\n",
       " (254, 0.33397849462365603),\n",
       " (255, 0.01876548800011732),\n",
       " (256, 0.41565569787127044),\n",
       " (257, 0.3340049250055967),\n",
       " (258, 0.009245302354291992),\n",
       " (259, 0.6668157201768771),\n",
       " (260, 0.6680309231468852),\n",
       " (261, 0.408576159316322),\n",
       " (262, 0.6668642951251649),\n",
       " (263, 0.6669076885996628),\n",
       " (264, 0.00019735543714229328),\n",
       " (265, 0.00022951572182694515),\n",
       " (266, 0.40849100891046497),\n",
       " (267, 0.7081918384578932),\n",
       " (268, 0.00017265193370165745),\n",
       " (269, 0.0004655493482309125),\n",
       " (270, 0.3968560647793379),\n",
       " (271, 0.3336000000000001),\n",
       " (272, 0.00018885741265344664),\n",
       " (273, 0.6876778293371985),\n",
       " (274, 0.6668434700612921),\n",
       " (275, 0.3335384194695106),\n",
       " (276, 0.3335447498238197),\n",
       " (277, 1.0125761235553006),\n",
       " (278, 0.3335254193878859),\n",
       " (279, 0.3334459079139931),\n",
       " (280, 0.3547213645304998),\n",
       " (281, 0.40859134363710486),\n",
       " (282, 0.4857243822685407),\n",
       " (283, 0.33376288659793824),\n",
       " (284, 0.0005649717514124294),\n",
       " (285, 0.6671910505156443),\n",
       " (286, 0.33347485611850186),\n",
       " (287, 0.2509661835748792),\n",
       " (288, 0.0001415227851684121),\n",
       " (289, 0.3335173598331494),\n",
       " (290, 0.6675184554230552),\n",
       " (291, 0.680319056705406),\n",
       " (292, 0.6669754992793907),\n",
       " (293, 0.016997987277457865),\n",
       " (294, 0.39003375773723203),\n",
       " (295, 0.33389418582912705),\n",
       " (296, 0.33350530237890524),\n",
       " (297, 0.34982998153477346),\n",
       " (298, 0.3348258706467663),\n",
       " (299, 0.666800840824724),\n",
       " (300, 0.666819036009955),\n",
       " (301, 0.014449156483465418),\n",
       " (302, 0.3338503964150294),\n",
       " (303, 0.816739712461886),\n",
       " (304, 0.8527361556425417),\n",
       " (305, 0.3335453324853368),\n",
       " (306, 0.3337617823479007),\n",
       " (307, 0.6688988095238098),\n",
       " (308, 0.692982456140351),\n",
       " (309, 0.00025627883136852895),\n",
       " (310, 0.39034067376914033),\n",
       " (311, 0.3335408022130015),\n",
       " (312, 0.667153284671533),\n",
       " (313, 0.1),\n",
       " (314, 0.3649726713059377),\n",
       " (315, 0.6668555597531799),\n",
       " (316, 0.3335461445697667),\n",
       " (317, 0.0007087172218284905),\n",
       " (318, 0.00032658393207054214),\n",
       " (319, 0.3335740072202167),\n",
       " (320, 0.3335313531353136),\n",
       " (321, 0.0008525149190110827),\n",
       " (322, 0.6668149026583656),\n",
       " (323, 0.0005053057099545225),\n",
       " (324, 0.333509172967587),\n",
       " (325, 0.33415502602026853),\n",
       " (326, 0.0043859649122807015),\n",
       " (327, 0.00046948356807511736),\n",
       " (328, 0.0002206531332744925),\n",
       " (329, 0.6887738760196093),\n",
       " (330, 0.6668796592119278),\n",
       " (331, 0.41139294455191333),\n",
       " (332, 0.683152388114392),\n",
       " (333, 0.03956054845899126),\n",
       " (334, 0.6668584947886695),\n",
       " (335, 0.33398058252427193),\n",
       " (336, 0.33368907861970837),\n",
       " (337, 0.4092563549799921),\n",
       " (338, 0.02258807733047055),\n",
       " (339, 0.6669162299309543),\n",
       " (340, 0.8166345500226487),\n",
       " (341, 0.33381111641981215),\n",
       " (342, 0.7031707326839837),\n",
       " (343, 0.00017123287671232877),\n",
       " (344, 0.40879864819638917),\n",
       " (345, 0.6668590853697648),\n",
       " (346, 0.00017937219730941703),\n",
       " (347, 0.0004484304932735426),\n",
       " (348, 0.0004329004329004329),\n",
       " (349, 0.3348104382077795),\n",
       " (350, 0.6963484911014277),\n",
       " (351, 0.33363563079403474),\n",
       " (352, 0.33349108692222756),\n",
       " (353, 0.4086279411851994),\n",
       " (354, 0.6061925567655566),\n",
       " (355, 0.4083822489367364),\n",
       " (356, 1.0004688232536336),\n",
       " (357, 0.0033783783783783786),\n",
       " (358, 0.3335234835520062),\n",
       " (359, 0.35256410256410264),\n",
       " (360, 0.00040064102564102563),\n",
       " (361, 0.4086187980592687),\n",
       " (362, 0.3431372549019609),\n",
       " (363, 0.33352446483180437),\n",
       " (364, 0.00022972662531587412),\n",
       " (365, 0.02814336026529267),\n",
       " (366, 0.3335131571060362),\n",
       " (367, 0.4756410484326502),\n",
       " (368, 0.334567901234568),\n",
       " (369, 0.6668898809523811),\n",
       " (370, 0.6712121212121214),\n",
       " (371, 0.3706882622739241),\n",
       " (372, 0.6928425716993212),\n",
       " (373, 0.0001751927119831815),\n",
       " (374, 0.3339332133573286),\n",
       " (375, 0.00017265193370165745),\n",
       " (376, 0.35697314262192276),\n",
       " (377, 0.34874635110428437),\n",
       " (378, 0.00020631318341242006),\n",
       " (379, 0.6667482327351824),\n",
       " (380, 0.0002632964718272775),\n",
       " (381, 0.3338898163606011),\n",
       " (382, 0.00022326412145568208),\n",
       " (383, 0.6668073532170327),\n",
       " (384, 0.4422692428522391),\n",
       " (385, 0.0003061849357011635),\n",
       " (386, 0.333576523994812),\n",
       " (387, 0.408398282964238),\n",
       " (388, 0.4084454902272233),\n",
       " (389, 0.6673258624478139),\n",
       " (390, 0.0008841732979664014),\n",
       " (391, 0.00034518467380048324),\n",
       " (392, 0.47856536446437914),\n",
       " (393, 0.00018191740949608878),\n",
       " (394, 0.40893604837307895),\n",
       " (395, 0.00030826140567200987),\n",
       " (396, 0.3334950409659337),\n",
       " (397, 0.00046882325363338024),\n",
       " (398, 0.40857476777369),\n",
       " (399, 0.3336350834842085),\n",
       " (400, 0.6683587140439934),\n",
       " (401, 0.00018726591760299626),\n",
       " (402, 0.6913005183846327),\n",
       " (403, 0.6667891406409473),\n",
       " (404, 0.00027693159789531985),\n",
       " (405, 0.6669580419580421),\n",
       " (406, 0.0005858230814294083),\n",
       " (407, 0.00016149870801033592),\n",
       " (408, 0.3335329341317366),\n",
       " (409, 7.63708568810142e-05),\n",
       " (410, 0.33409090909090916),\n",
       " (411, 0.6671883150756392),\n",
       " (412, 0.6668842945230324),\n",
       " (413, 0.0001795654516071108),\n",
       " (414, 0.3335381674177251),\n",
       " (415, 0.4091224163379889),\n",
       " (416, 0.0002929973630237328),\n",
       " (417, 8.308408109006314e-05),\n",
       " (418, 0.07632109731072029),\n",
       " (419, 0.3641065012568281),\n",
       " (420, 0.333708849668294),\n",
       " (421, 0.3701340195867238),\n",
       " (422, 0.00018328445747800586),\n",
       " (423, 0.0002203128442388191),\n",
       " (424, 0.667190226876091),\n",
       " (425, 0.6668075911311538),\n",
       " (426, 0.34649307741728674),\n",
       " (427, 0.0006191950464396285),\n",
       " (428, 0.4083655375033753),\n",
       " (429, 0.0002878526194588371),\n",
       " (430, 0.00020512820512820512),\n",
       " (431, 0.00030892801977139327),\n",
       " (432, 0.35984786850220335),\n",
       " (433, 0.6678714859437753),\n",
       " (434, 0.00026232948583420777),\n",
       " (435, 0.000708215297450425),\n",
       " (436, 0.0011947431302270011),\n",
       " (437, 0.34968781320683845),\n",
       " (438, 0.00023062730627306272),\n",
       " (439, 0.0004816955684007707),\n",
       " (440, 0.00039603960396039607),\n",
       " (441, 0.00025759917568263783),\n",
       " (442, 0.6668160318645757),\n",
       " (443, 0.00040048057669203043),\n",
       " (444, 0.5835393489905234),\n",
       " (445, 0.0005817335660267597),\n",
       " (446, 0.6668154540494968),\n",
       " (447, 0.333719881458575),\n",
       " (448, 0.00023126734505087883),\n",
       " (449, 0.33380704247591986),\n",
       " (450, 0.0001528350909368791),\n",
       " (451, 0.030525486396239046),\n",
       " (452, 0.00014452955629426219),\n",
       " (453, 0.6669469357249628),\n",
       " (454, 0.00039824771007566706),\n",
       " (455, 0.33348361887586425),\n",
       " (456, 0.33599290780141855),\n",
       " (457, 0.6668242710795904),\n",
       " (458, 0.012866302872049293),\n",
       " (459, 0.33353729009450006),\n",
       " (460, 0.0006357279084551812),\n",
       " (461, 0.33348921797869585),\n",
       " (462, 0.01688666399746778),\n",
       " (463, 0.00015634771732332708),\n",
       " (464, 0.02857142857142857),\n",
       " (465, 0.00017265193370165745),\n",
       " (466, 0.6916767980339643),\n",
       " (467, 0.6668292947362716),\n",
       " (468, 0.6816810871143686),\n",
       " (469, 0.8167702536151918),\n",
       " (470, 0.00016043638697256537),\n",
       " (471, 0.00018304960644334616),\n",
       " (472, 0.666935990663435),\n",
       " (473, 0.00014509576320371445),\n",
       " (474, 0.023809523809523808),\n",
       " (475, 0.6668176328502418),\n",
       " (476, 0.33378317588843914),\n",
       " (477, 0.00018453589223103894),\n",
       " (478, 0.6668116362230601),\n",
       " (479, 0.3348104382077795),\n",
       " (480, 0.33351041851130403),\n",
       " (481, 0.00022914757103574703),\n",
       " (482, 0.00046446818392940084),\n",
       " (483, 0.695315832831517),\n",
       " (484, 0.40840180596892905),\n",
       " (485, 0.3334951718185252),\n",
       " (486, 0.8666666666666669),\n",
       " (487, 0.33351638293977676),\n",
       " (488, 0.3336420705979213),\n",
       " (489, 0.00045454545454545455),\n",
       " (490, 0.33359538784067094),\n",
       " (491, 0.6682926829268294),\n",
       " (492, 0.25),\n",
       " (493, 0.00019735543714229328),\n",
       " (494, 0.0001282873636946761),\n",
       " (495, 0.6673934108527133),\n",
       " (496, 0.0013157894736842105),\n",
       " (497, 0.33354275741710304),\n",
       " (498, 0.446881749684282),\n",
       " (499, 0.0006920415224913495),\n",
       " (500, 0.6668876123140376),\n",
       " (501, 0.3445692883895132),\n",
       " (502, 0.25033422459893045),\n",
       " (503, 0.6668453657374317),\n",
       " (504, 0.00423728813559322),\n",
       " (505, 0.33355605048255393),\n",
       " (506, 0.0011723329425556857),\n",
       " (507, 0.6668082696120081),\n",
       " (508, 0.6790526243234084),\n",
       " (509, 0.0002627430373095113),\n",
       " (510, 0.33363444745558574),\n",
       " (511, 0.7119500412290145),\n",
       " (512, 0.6814692405116827),\n",
       " (513, 0.6668078896577698),\n",
       " (514, 0.00028538812785388126),\n",
       " (515, 0.0002340276152586005),\n",
       " (516, 0.0003303600925008259),\n",
       " (517, 0.0002448579823702253),\n",
       " (518, 0.6668350451815683),\n",
       " (519, 0.4093846541002267),\n",
       " (520, 0.0005128205128205128),\n",
       " (521, 0.00024108003857280618),\n",
       " (522, 0.0004042037186742118),\n",
       " (523, 0.7010408839486798),\n",
       " (524, 0.0003486750348675035),\n",
       " (525, 0.3498347577302447),\n",
       " (526, 0.0003098853424233034),\n",
       " (527, 0.40850549210995357),\n",
       " (528, 0.5836114974501624),\n",
       " (529, 0.33354997111496254),\n",
       " (530, 0.3599059471651358),\n",
       " (531, 0.707149583568209),\n",
       " (532, 0.00025220680958385876),\n",
       " (533, 0.0002955082742316785),\n",
       " (534, 0.6668617125024383),\n",
       " (535, 0.6668015102481124),\n",
       " (536, 0.00017262213015708613),\n",
       " (537, 0.33402489626556026),\n",
       " (538, 0.0002575328354365182),\n",
       " (539, 0.333511586452763),\n",
       " (540, 0.666887807754681),\n",
       " (541, 0.3504309075123611),\n",
       " (542, 0.33377916480903563),\n",
       " (543, 0.3572024980490877),\n",
       " (544, 0.6855641026561641),\n",
       " (545, 0.00018315018315018315),\n",
       " (546, 0.340966921119593),\n",
       " (547, 0.33392963625521777),\n",
       " (548, 0.43621705465810556),\n",
       " (549, 0.0001547029702970297),\n",
       " (550, 0.005050505050505051),\n",
       " (551, 0.3336881949373079),\n",
       " (552, 0.0004389815627743635),\n",
       " (553, 0.333668117397612),\n",
       " (554, 0.0002967359050445104),\n",
       " (555, 0.0001908761213972132),\n",
       " (556, 0.3334673815907061),\n",
       " (557, 0.25027449903925336),\n",
       " (558, 0.0003316749585406302),\n",
       " (559, 0.00019774569903104609),\n",
       " (560, 0.5775391266022792),\n",
       " (561, 0.3619523955246178),\n",
       " (562, 0.000243605359317905),\n",
       " (563, 0.00015785319652722967),\n",
       " (564, 0.0002069108214359611),\n",
       " (565, 0.33357273960577777),\n",
       " (566, 0.333625133741854),\n",
       " (567, 0.00016857720836142953),\n",
       " (568, 0.7001159969362614),\n",
       " (569, 0.3504002841136848),\n",
       " (570, 0.4083926739463926),\n",
       " (571, 0.5837758112094397),\n",
       " (572, 0.3502185267232945),\n",
       " (573, 0.40835643364543545),\n",
       " (574, 0.6668907814134172),\n",
       " (575, 0.0001973164956590371),\n",
       " (576, 0.0002955082742316785),\n",
       " (577, 0.6669110459433042),\n",
       " (578, 0.000468384074941452),\n",
       " (579, 0.33353385468885777),\n",
       " (580, 0.44909442813431),\n",
       " (581, 0.6668288989833443),\n",
       " (582, 0.43101726088233344),\n",
       " (583, 0.3335646541753413),\n",
       " (584, 0.00012818869375721061),\n",
       " (585, 0.05860494724150757),\n",
       " (586, 0.0015625),\n",
       " (587, 0.6667711162175338),\n",
       " (588, 0.40878020535748005),\n",
       " (589, 0.3529700796420098),\n",
       " (590, 0.35735494425091474),\n",
       " (591, 0.3336666666666668),\n",
       " (592, 0.35007149863752),\n",
       " (593, 0.018701792809413986),\n",
       " (594, 0.695993067347366),\n",
       " (595, 0.6669400400947696),\n",
       " (596, 0.6802582097577409),\n",
       " (597, 0.33406007751937994),\n",
       " (598, 0.0008130081300813008),\n",
       " (599, 0.01339534416849088),\n",
       " (600, 0.68169653069154),\n",
       " (601, 0.33353301384451556),\n",
       " (602, 0.6668756967670013),\n",
       " (603, 0.00015403573629081948),\n",
       " (604, 0.6668592335836705),\n",
       " (605, 0.0011560693641618498),\n",
       " (606, 0.3368298368298369),\n",
       " (607, 0.3335798816568048),\n",
       " (608, 0.33361921097770164),\n",
       " (609, 0.40958697854953907),\n",
       " (610, 0.8180256329154936),\n",
       " (611, 0.3593583890869265),\n",
       " (612, 0.3338458909960705),\n",
       " (613, 0.666858310974831),\n",
       " (614, 0.0005165289256198347),\n",
       " (615, 0.6668040481751158),\n",
       " (616, 0.008130081300813009),\n",
       " (617, 0.33375832270859906),\n",
       " (618, 0.6668354430379748),\n",
       " (619, 0.0005868544600938967),\n",
       " (620, 0.00017117425539198904),\n",
       " (621, 0.34432234432234443),\n",
       " (622, 0.3337221358216694),\n",
       " (623, 0.0005224660397074191),\n",
       " (624, 0.3341509948214773),\n",
       " (625, 0.00016600265604249667),\n",
       " (626, 0.032746119853149784),\n",
       " (627, 0.6669880034275923),\n",
       " (628, 0.00015865460891638903),\n",
       " (629, 0.668355855855856),\n",
       " (630, 0.00018422991893883567),\n",
       " (631, 0.0002008838891120932),\n",
       " (632, 0.049122792882208485),\n",
       " (633, 0.0009250693802035153),\n",
       " (634, 0.40841347051011345),\n",
       " (635, 0.0001347164219318335),\n",
       " (636, 0.0002108370229812355),\n",
       " (637, 0.0009596928982725527),\n",
       " (638, 0.00016241676140977748),\n",
       " (639, 0.00037750094375235937),\n",
       " (640, 0.8166550344216256),\n",
       " (641, 0.000550357732526142),\n",
       " (642, 0.03601286021942063),\n",
       " (643, 0.6668463611859841),\n",
       " (644, 0.6667888264516656),\n",
       " (645, 0.6668055748483588),\n",
       " (646, 0.0001789228842368939),\n",
       " (647, 0.028342677340283323),\n",
       " (648, 0.000231000231000231),\n",
       " (649, 0.0007942811755361397),\n",
       " (650, 0.00016812373907195696),\n",
       " (651, 0.003215434083601286),\n",
       " (652, 0.33744855967078197),\n",
       " (653, 0.3340740740740742),\n",
       " (654, 0.3771955696788498),\n",
       " (655, 0.40833601745745896),\n",
       " (656, 0.00015554518587649713),\n",
       " (657, 0.3455187569006028),\n",
       " (658, 0.3337148670990717),\n",
       " (659, 0.6824546599005578),\n",
       " (660, 0.6668506593069612),\n",
       " (661, 0.00027464982147761604),\n",
       " (662, 0.0001707941929974381),\n",
       " (663, 0.035447879334683095),\n",
       " (664, 0.6667787491593815),\n",
       " (665, 0.66684924837198),\n",
       " (666, 0.001557632398753894),\n",
       " (667, 0.33360470375395757),\n",
       " (668, 0.40850222647198897),\n",
       " (669, 0.41056310527867784),\n",
       " (670, 0.013648517982267353),\n",
       " (671, 0.4299874208986456),\n",
       " (672, 0.33363363363363374),\n",
       " (673, 0.33353994490358135),\n",
       " (674, 0.3337874659400546),\n",
       " (675, 0.40837065952896334),\n",
       " (676, 0.33346163715678734),\n",
       " (677, 0.33346229902845853),\n",
       " (678, 0.6919673710774892),\n",
       " (679, 0.4085474229795675),\n",
       " (680, 0.3645608802286002),\n",
       " (681, 0.0001373060551970342),\n",
       " (682, 0.00037257824143070045),\n",
       " (683, 0.6955424930393247),\n",
       " (684, 0.3500000000000001),\n",
       " (685, 0.33365261813537683),\n",
       " (686, 0.0005984440454817474),\n",
       " (687, 0.6669750231267347),\n",
       " (688, 0.0002525252525252525),\n",
       " (689, 0.00040064102564102563),\n",
       " (690, 0.3335057768580791),\n",
       " (691, 0.6669831223628694),\n",
       " (692, 0.0002744990392533626),\n",
       " (693, 0.002564102564102564),\n",
       " (694, 0.3335381674177251),\n",
       " (695, 0.7348433232500111),\n",
       " (696, 0.3560092319684818),\n",
       " (697, 0.00015740594994490792),\n",
       " (698, 0.44116833179936654),\n",
       " (699, 0.00021934634788330776),\n",
       " (700, 0.7171334443281011),\n",
       " (701, 0.0001913143294432753),\n",
       " (702, 0.8167172340610005),\n",
       " (703, 0.00021303792074989347),\n",
       " (704, 0.333493769720306),\n",
       " (705, 0.0004488330341113106),\n",
       " (706, 0.5774583539280608),\n",
       " (707, 0.00027808676307007786),\n",
       " (708, 0.6683181577695959),\n",
       " (709, 0.0005260389268805891),\n",
       " (710, 0.00018412815319462345),\n",
       " (711, 0.7057367387794964),\n",
       " (712, 0.01951053976505291),\n",
       " (713, 0.00015688735487919673),\n",
       " (714, 0.3335772357723578),\n",
       " (715, 0.6668690548471972),\n",
       " (716, 0.33358073560943435),\n",
       " (717, 0.3342948717948719),\n",
       " (718, 0.33350185372430075),\n",
       " (719, 0.00045682960255824577),\n",
       " (720, 0.0006626905235255136),\n",
       " (721, 0.6668810289389069),\n",
       " (722, 0.00040749796251018743),\n",
       " (723, 0.04775875955235997),\n",
       " (724, 0.3986316089267219),\n",
       " (725, 0.0002842524161455372),\n",
       " (726, 0.4084834739069486),\n",
       " (727, 0.00014452955629426219),\n",
       " (728, 0.35229506093447105),\n",
       " (729, 0.00015518311607697082),\n",
       " (730, 0.3468100733207724),\n",
       " (731, 0.6668192219679636),\n",
       " (732, 0.6668979875086747),\n",
       " (733, 0.00013931457230426304),\n",
       " (734, 0.33373301358912877),\n",
       " (735, 0.3448931352848767),\n",
       " (736, 0.4083832432303947),\n",
       " (737, 0.33487416538264003),\n",
       " (738, 0.01694915254237288),\n",
       " (739, 0.6744791666666669),\n",
       " (740, 0.33348584210258764),\n",
       " (741, 0.33365180467091304),\n",
       " (742, 0.0024330900243309003),\n",
       " (743, 0.00016079755587715066),\n",
       " (744, 0.33492822966507185),\n",
       " (745, 0.408505956013979),\n",
       " (746, 0.6923977722598526),\n",
       " (747, 0.6793807758381333),\n",
       " (748, 0.408679139235944),\n",
       " (749, 0.00046598322460391424),\n",
       " (750, 0.6034154357968498),\n",
       " (751, 0.33374792703150924),\n",
       " (752, 0.00016390755613833797),\n",
       " (753, 0.7296784886480592),\n",
       " (754, 0.00046146746654360867),\n",
       " (755, 0.6955477695195398),\n",
       " (756, 0.3335587108406582),\n",
       " (757, 0.05550492182897876),\n",
       " (758, 0.3630145845968933),\n",
       " (759, 0.00014570887367040654),\n",
       " (760, 0.4084607400070965),\n",
       " (761, 0.6670511341791621),\n",
       " (762, 0.6668225513120293),\n",
       " (763, 0.00042087542087542086),\n",
       " (764, 0.00018278194114421494),\n",
       " (765, 0.0001811922449719152),\n",
       " (766, 0.00029239766081871346),\n",
       " (767, 1.0002608242044864),\n",
       " (768, 0.33394495412844044),\n",
       " (769, 0.3335556049492481),\n",
       " (770, 0.02615077119589014),\n",
       " (771, 0.00020024028834601522),\n",
       " (772, 0.00030048076923076925),\n",
       " (773, 0.6669677807889192),\n",
       " (774, 0.3335286458333334),\n",
       " (775, 0.031135556193810674),\n",
       " (776, 0.0016129032258064516),\n",
       " (777, 0.6965095225905257),\n",
       " (778, 0.3337084271067768),\n",
       " (779, 0.00026504108136761196),\n",
       " (780, 0.0001650709805216243),\n",
       " (781, 0.33373173970783543),\n",
       " (782, 0.35381981133637574),\n",
       " (783, 0.43340223066414835),\n",
       " (784, 0.6670129270544785),\n",
       " (785, 0.333561331509348),\n",
       " (786, 0.6780303030303032),\n",
       " (787, 0.3336016456488687),\n",
       " (788, 0.6923567385381968),\n",
       " (789, 0.00016059097478721696),\n",
       " (790, 0.41138308670210755),\n",
       " (791, 0.34552845528455295),\n",
       " (792, 0.025490188342416883),\n",
       " (793, 0.00017670966601873123),\n",
       " (794, 0.680783761956851),\n",
       " (795, 0.00036075036075036075),\n",
       " (796, 0.021739130434782608),\n",
       " (797, 0.0004675081813931744),\n",
       " (798, 0.001148105625717566),\n",
       " (799, 0.6672005694963519),\n",
       " (800, 0.6673934108527133),\n",
       " (801, 0.00015190642564180464),\n",
       " (802, 0.0008136696501220504),\n",
       " (803, 0.00014110342881332017),\n",
       " (804, 0.6669166666666668),\n",
       " (805, 0.33403954802259894),\n",
       " (806, 0.00019293845263360988),\n",
       " (807, 0.3525976283941201),\n",
       " (808, 0.6669034090909093),\n",
       " (809, 0.00012850167052171679),\n",
       " (810, 0.0003479471120389701),\n",
       " (811, 0.00018188432157148054),\n",
       " (812, 0.3334677600035848),\n",
       " (813, 0.6667409277687016),\n",
       " (814, 0.000141622999575131),\n",
       " (815, 0.0002557544757033248),\n",
       " (816, 0.35312500652945455),\n",
       " (817, 0.00022376370552696352),\n",
       " (818, 0.33467381590705997),\n",
       " (819, 0.000493339911198816),\n",
       " (820, 0.00013408420488066506),\n",
       " (821, 0.6805901321736764),\n",
       " (822, 0.0002127659574468085),\n",
       " (823, 0.3334671663097788),\n",
       " (824, 0.00030883261272390367),\n",
       " (825, 0.00027129679869777537),\n",
       " (826, 0.3334644636768949),\n",
       " (827, 0.00015605493133583021),\n",
       " (828, 0.8167239053196332),\n",
       " (829, 0.00016894745734076703),\n",
       " (830, 0.6669041963578782),\n",
       " (831, 0.6667726100928772),\n",
       " (832, 0.000117813383600377),\n",
       " (833, 0.6668442550168711),\n",
       " (834, 0.6668062534896707),\n",
       " (835, 0.000628140703517588),\n",
       " (836, 0.667030700157748),\n",
       " (837, 0.0013774104683195593),\n",
       " (838, 0.3334501967200344),\n",
       " (839, 0.00014513788098693758),\n",
       " (840, 0.6668269230769233),\n",
       " (841, 0.5774940713178973),\n",
       " (842, 0.003003003003003003),\n",
       " (843, 0.0008424599831508003),\n",
       " (844, 0.333550159005493),\n",
       " (845, 0.00016700066800267202),\n",
       " (846, 0.0002305209774089442),\n",
       " (847, 0.0003575259206292456),\n",
       " (848, 0.33408919123204844),\n",
       " (849, 0.33368719037508854),\n",
       " (850, 0.33347570235383456),\n",
       " (851, 0.0001426330052774212),\n",
       " (852, 0.0002516356316054353),\n",
       " (853, 0.0003368137420006736),\n",
       " (854, 0.40852476267840543),\n",
       " (855, 0.00021598272138228941),\n",
       " (856, 0.6668123543123545),\n",
       " (857, 0.0004310344827586207),\n",
       " (858, 0.6683760683760686),\n",
       " (859, 0.6799219935554437),\n",
       " (860, 0.024490817336864822),\n",
       " (861, 0.00024894199651481205),\n",
       " (862, 5.130046683424819e-05),\n",
       " (863, 0.40844658512973653),\n",
       " (864, 0.3335347026446504),\n",
       " (865, 0.027471150389502055),\n",
       " (866, 0.6676686706746828),\n",
       " (867, 0.3334435626102294),\n",
       " (868, 0.0002723311546840959),\n",
       " (869, 0.0002948982601002654),\n",
       " (870, 0.6667451349654742),\n",
       " (871, 0.024106847747246384),\n",
       " (872, 0.00030003000300030005),\n",
       " (873, 1.000178221350918),\n",
       " (874, 0.00015269506794930523),\n",
       " (875, 0.00018712574850299402),\n",
       " (876, 0.33352906635349394),\n",
       " (877, 0.42747905969463224),\n",
       " (878, 0.00030349013657056146),\n",
       " (879, 0.3337874659400546),\n",
       " (880, 0.3336533333333334),\n",
       " (881, 0.00016079755587715066),\n",
       " (882, 0.0003225806451612903),\n",
       " (883, 0.4084616010440678),\n",
       " (884, 0.0009606147934678194),\n",
       " (885, 0.00029120559114735004),\n",
       " (886, 0.00037439161362785476),\n",
       " (887, 0.0004798464491362764),\n",
       " (888, 0.6669344759864312),\n",
       " (889, 0.02798836830104057),\n",
       " (890, 0.0006480881399870382),\n",
       " (891, 0.00017280110592707794),\n",
       " (892, 0.4083856908485841),\n",
       " (893, 0.6671453646082657),\n",
       " (894, 0.333550961189699),\n",
       " (895, 0.00017844396859386153),\n",
       " (896, 0.0002967359050445104),\n",
       " (897, 0.00030674846625766873),\n",
       " (898, 0.3337472406181016),\n",
       " (899, 0.3335228708617641),\n",
       " (900, 0.0005889281507656066),\n",
       " (901, 0.5974429818571358),\n",
       " (902, 0.00014496955639315743),\n",
       " (903, 0.0008237232289950577),\n",
       " (904, 0.00015337423312883436),\n",
       " (905, 0.0001626280696048138),\n",
       " (906, 0.0014771048744460858),\n",
       " (907, 0.00020542317173377156),\n",
       " (908, 0.023058501658718762),\n",
       " (909, 0.00017540782318891423),\n",
       " (910, 0.0002153316106804479),\n",
       " (911, 0.6686351706036747),\n",
       " (912, 0.0001306506401881369),\n",
       " (913, 0.0003980891719745223),\n",
       " (914, 0.4125401359574252),\n",
       " (915, 0.0001626280696048138),\n",
       " (916, 0.016666666666666666),\n",
       " (917, 0.003278688524590164),\n",
       " (918, 0.3336187214611873),\n",
       " (919, 0.33349707985371985),\n",
       " (920, 0.666801003044958),\n",
       " (921, 0.0007122507122507123),\n",
       " (922, 0.6670812603648426),\n",
       " (923, 0.03150001817972977),\n",
       " (924, 0.00025806451612903227),\n",
       " (925, 0.0006451612903225806),\n",
       " (926, 0.00024067388688327315),\n",
       " (927, 0.00025075225677031093),\n",
       " (928, 0.0006688963210702341),\n",
       " (929, 0.33346604733466056),\n",
       " (930, 0.3764121944142328),\n",
       " (931, 0.33374672729778154),\n",
       " (932, 0.35182462971781864),\n",
       " (933, 0.6668819519196271),\n",
       " (934, 0.33361542078044204),\n",
       " (935, 0.333598023645668),\n",
       " (936, 0.023073666154282888),\n",
       " (937, 0.35323059068424045),\n",
       " (938, 0.0002033760423022168),\n",
       " (939, 0.4024854509943508),\n",
       " (940, 0.0002759381898454746),\n",
       " (941, 0.3459915611814347),\n",
       " (942, 0.335897435897436),\n",
       " (943, 0.00028208744710860365),\n",
       " (944, 0.3645187574393391),\n",
       " (945, 0.40839891555800373),\n",
       " (946, 0.0001511030522816561),\n",
       " (947, 0.00028776978417266187),\n",
       " (948, 0.012327984587887685),\n",
       " (949, 0.0007692307692307692),\n",
       " (950, 1.000158780565259),\n",
       " (951, 0.41049044293023074),\n",
       " (952, 0.7025972816954335),\n",
       " (953, 0.01464646826774674),\n",
       " (954, 0.0026109660574412533),\n",
       " (955, 0.4307426778396146),\n",
       " (956, 0.3652613783787672),\n",
       " (957, 0.0002498750624687656),\n",
       " (958, 0.3579105854949931),\n",
       " (959, 0.40837455309012566),\n",
       " (960, 0.3335971855760775),\n",
       " (961, 0.33350767085076716),\n",
       " (962, 0.00023986567522187575),\n",
       " (963, 0.6810654209116666),\n",
       " (964, 0.028757864743039638),\n",
       " (965, 0.35492132797744536),\n",
       " (966, 0.0005076142131979696),\n",
       " (967, 0.0005443658138268917),\n",
       " (968, 0.333535844471446),\n",
       " (969, 1.0001365187713314),\n",
       " (970, 0.3336474036850922),\n",
       " (971, 0.00017073587160662456),\n",
       " (972, 0.7305334904092332),\n",
       " (973, 0.3335519603556334),\n",
       " (974, 0.37848991012611727),\n",
       " (975, 0.3337404994571119),\n",
       " (976, 0.6668091777112728),\n",
       " (977, 0.33350210970464145),\n",
       " (978, 0.3335850956696879),\n",
       " (979, 0.3374655647382921),\n",
       " (980, 0.3335493160547157),\n",
       " (981, 0.4085050298733624),\n",
       " (982, 0.682750229158518),\n",
       " (983, 0.3336707152496627),\n",
       " (984, 0.6669385535617185),\n",
       " (985, 0.7386126181216008),\n",
       " (986, 0.0006016847172081829),\n",
       " (987, 0.25067249495628785),\n",
       " (988, 0.3334857258965763),\n",
       " (989, 0.6667950858268056),\n",
       " (990, 0.00013664935774801857),\n",
       " (991, 0.012150136677641837),\n",
       " (992, 0.8167678777264238),\n",
       " (993, 0.33346998269108147),\n",
       " (994, 0.3337789661319074),\n",
       " (995, 0.0010152284263959391),\n",
       " (996, 0.3335349462365592),\n",
       " (997, 0.009708737864077669),\n",
       " (998, 0.40848155381819007),\n",
       " (999, 0.00017497812773403323),\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(cosine_sim_mixed[2]+1/abs(year_list-year[2]))) # generate index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations_rating_year(title, cosine_sim=cosine_sim_mixed):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    rating = rating_[idx]\n",
    "    year_list_ = year_list\n",
    "    year_ = year[idx]\n",
    "    \n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]+1/(abs(year_list_-year_+1))))+ rating\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 20 most similar movies\n",
    "    sim_scores = sim_scores[1:21]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df2['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119                             Batman Begins\n",
       "65                            The Dark Knight\n",
       "3073                        Romeo Is Bleeding\n",
       "1196                             The Prestige\n",
       "1253                            Kiss of Death\n",
       "1149                          American Hustle\n",
       "761                            Righteous Kill\n",
       "1742                           Brick Mansions\n",
       "3062                              Deuces Wild\n",
       "3326                           Black November\n",
       "3725                              The Sweeney\n",
       "2543                                 Cop Land\n",
       "2388                               I Am Wrath\n",
       "2154                             Street Kings\n",
       "405     The Fast and the Furious: Tokyo Drift\n",
       "1765                          The Newton Boys\n",
       "1278                               The Gunman\n",
       "3828                        Menace II Society\n",
       "4663                                  Bronson\n",
       "4408                           Jimmy and Judy\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_rating_year('The Dark Knight Rises', cosine_sim_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
